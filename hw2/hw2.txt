I found that mainly there are three difficult points in solving this problem. The first one is, for a non-terminal with more than one rules, how to remember which are the ones I have tried and which one I should try next if the current one does not work, especially if the rule we are trying leads to another non-terminal which requires further parsing. Next problem is that how to make sure the current rule we are using is not a blind alley rule or that it leads to an infinite loop. The last one is that for a rule with more than one symbols(at least one non-terminal), after parsing the non-terminal, how to go back and match the terminal or parse the non-terminal following.  

At the beginning, I thought I could keep a record of all the paths I have tried into a list in the format of a list of (non_ter, rule), which records all the derivations. Whenever we need to choose a rule for a non-terminal, we will first check if the current path belongs to the list of all paths tried before. However, this will take a large amount of time especially as the number of rules available increases as this method will need to iterate through every incorrect rule before finding the correct one. It will also require lots of space since it will need to remember all the incorrect paths tried. Therefore, I thought I should not continue with this method, especially after professor Eggert talked about in the case of disjunction, we should use the format: let r = pB accept ts in if r then r else pC acc ts, where it will call another function to parse the rule to see if it is a match, and parse the next rule if the function called returns None. 

This leads to my first function match_rule which takes in a start symbol, the rules function given, the rule list for the start symbol (by applying the start symbol to the rules function), acceptor, derivation and fragment given. It will recurse on the rule list and call my second function match_ter with the updated derivation to see if this rule will successfully match the prefix of the fragment. If match_ter succeeds, it will return whatever match_ter returns(elaborated further later), if not, it will call match_ter on the next rule with the previous derivation.

To address the second problem, since my initial thought was to do a width-first search which will end up in infinite loop for the rule such as the Expr->[Term;Binop;Expr] since the Expr term in the rule will keep giving the same rule. I first thought to add another parameter for the helper function which is the length of the terms produced by current derivation, and check if this number is larger than the number of terms in the fragment given before adding this rule to the current path. However, similar to my previous approach for addressing the first problem, this will take lots of extra time and space so I gave up on this method.

My initial idea to address the third problem, as mentioned before, was to conduct a width-first search, so it only became a problem after I realized that I need to do a depth-first search. After professor Eggert talked about the problem in class, I realized that I can make the function remember where it was last at by combining the matcher for the rest of the rule with the accept function, which is passed into the matcher for individual element. So this is what I did in my second function, where it first decides if the rule passed in has any token inside. If there is, it will then see if there is any token in the fragment passed. If there is no more token in the fragment, it means that the rule has more to be matched while the fragment is empty already, so this is not a match. If there is any token in the fragment, it will then look at the rule being matched. If the first element is a non-terminal, it will use the previous match_rule function to further evaluate until it reaches a terminal; if the first element is terminal, if it is the same as the first element in the fragment, it will continue to match the next element in the rule and the fragment by calling the match_rule function, while remembering the rest of the current rule by combing a match_ter function(with parameters of rule functin and the rest of the rule) with the acceptor function, and pass this as the updated acceptor function into the match_rule function. However, if it is not the same, it will just immediately return None, making match_rule to match the next element. If there is no more element in the rule, it will immediately try to pass the fragment to the acceptor, which, in the case that only a part of the rule is matched, will call the match_ter we previously combined in the accept function to match the  elements in the rest of the rule.

And to sum up, since the two functions I described above requires them to call each other recursively, they will need to be declared using let rec … and … grammar. What the function parse_prefix does is just to call the first function, match_rule, which will then call itself and match_ter recursively.

One of the weaknesses may be that though I have tried to reduce the amount of time and space used by changing the width-first search I originally had in mind into a depth-first search, the function still needs lots of time to run as the number of rules it need to try out increases (especially when the rules that will be matched are at the end of the rule list).

Another would be that it may still run into infinite loop if there is a grammar such as Expr -> [N Expr; N Binop; N Term], where the first element in the rule is the same non-terminal element we are trying to parse, or Expr -> [N Lvalue; N Term]; Lvalue -> [N Expr; N Term], where the two rules will form a loop. In this kind of cases, the parse will keep parsing the first element and never get to the rest of the rule or rules.
